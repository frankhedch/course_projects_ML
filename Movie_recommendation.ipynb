{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1  TSAK DEFINITION\n",
    "#This project is used to recommend movies for a certain user based on his/her previous rating history.\n",
    "#The input is the matrix from dataset 'Movielens', which records 100,000 rating information from 671 users and 9066 movies.\n",
    "#I hope this project is not too small..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2 TOOLS AND INFRASTRUCTURE\n",
    "#Using Pandas to interprete the dataset and sklearn for some data processing.\n",
    "#Using python language.\n",
    "\n",
    "#Pre precessing: 1 Split dataset into 80% and 20% as training set and test set respectively.\n",
    "#                2 Construct user-movie matrix for predicting ratings.      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3  EVALUATION METRIC\n",
    "#Using training set to train the parameters and use root mean square error to evaluate the model.\n",
    "#Using Gradient Descent to optimaze the loss function and find the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4  APPROACH\n",
    "#1 Different to simple collabrative filtering, this project use left-singualr and right-singular \n",
    "#matrixs to replace user-movie and movie-user matrix.\n",
    "\n",
    "#2 This project tries different ways to calculate similarity and find the best one.\n",
    "#3 This project further use svd++ algorithm and select model by Gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5 BASELINE\n",
    "#Simple collabrative filtering algorithm gives rmse 1.82."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#6 Conclusion\n",
    "#Final result: rmse 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pylab as plt \n",
    "import math\n",
    "import random\n",
    "from numpy import *\n",
    "import sys\n",
    "import os\n",
    "from pandas import Series,DataFrame\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from numpy.random import random\n",
    "import csv\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.random import normal,random,uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "r = requests.get(data_url)\n",
    "mr_zip_file = 'ml-latest-small.zip'\n",
    "with open(mr_zip_file, 'wb') as out_file:\n",
    "    out_file.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(mr_zip_file,\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"data\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['links.csv', 'movies.csv', 'ratings.csv', 'README.txt', 'tags.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('./data/ml-latest-small')) \n",
    "with  open('./data/ml-latest-small/links.csv', 'r') as f:\n",
    "    _links = f.readlines()\n",
    "with  open('./data/ml-latest-small/movies.csv', 'r') as f:\n",
    "    _movies = f.readlines()\n",
    "with  open('./data/ml-latest-small/ratings.csv', 'r') as f:\n",
    "    _ratings = f.readlines()    \n",
    "with  open('./data/ml-latest-small/tags.csv', 'r') as f:\n",
    "    _tags = f.readlines()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnames = ['user_id', 'movie_id', 'rating', 'timestamp']  \n",
    "ratings = pd.read_table('./data/ml-latest-small/ratings.csv', sep=',', header=None, names=rnames,engine = 'python') \n",
    "ratings=ratings.drop([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = ratings.filter(regex='user_id|movie_id|rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id movie_id rating   timestamp\n",
      "1        1       31    2.5  1260759144\n",
      "2        1     1029    3.0  1260759179\n",
      "3        1     1061    3.0  1260759182\n",
      "4        1     1129    2.0  1260759185\n",
      "5        1     1172    4.0  1260759205\n",
      "6        1     1263    2.0  1260759151\n",
      "7        1     1287    2.0  1260759187\n",
      "8        1     1293    2.0  1260759148\n",
      "9        1     1339    3.5  1260759125\n",
      "10       1     1343    2.0  1260759131\n"
     ]
    }
   ],
   "source": [
    "h10 = ratings.head(10)  \n",
    "print(h10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id movie_id  rating\n",
      "count   100004   100004  100004\n",
      "unique     671     9066      10\n",
      "top        547      356     4.0\n",
      "freq      2391      341   28750\n"
     ]
    }
   ],
   "source": [
    "print (data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(fliename):\n",
    "    rates = []\n",
    "    with open(fliename,encoding='utf-8') as csvfile:\n",
    "        content = csv.reader(csvfile)\n",
    "        for row in content:\n",
    "            rates.append([row[0],row[1],row[2]])\n",
    "    return rates[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRating(char_array):\n",
    "    rate_array = []\n",
    "    for row in char_array:\n",
    "        rate_array.append([int(row[0]),int(row[1]),float(row[2])])\n",
    "    return rate_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMovieInfo(char_array):\n",
    "    movie_Id = []\n",
    "    movie_title = []\n",
    "    for row in char_array:\n",
    "        movie_Id.append([int(row[0])])\n",
    "        movie_title.append([row[1]])\n",
    "    return np.array(movie_Id), movie_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies = read_file('./data/ml-latest-small/movies.csv')\n",
    "[movieId , movie_title] =  getMovieInfo(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rateInfo = read_file('./data/ml-latest-small/ratings.csv')\n",
    "rate = getRating(rateInfo)\n",
    "rate_train, rate_test =train_test_split(rate,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bi={}  \n",
    "bu={}  \n",
    "qi={}  \n",
    "pu={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_sp=20\n",
    "ave=np.mean(np.array(rate_train)[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_matrix = np.zeros((len(movieId),rate[-1][0]))\n",
    "test_matrix = np.zeros((len(movieId),rate[-1][0]))\n",
    "for rate_row in rate_train:\n",
    "    row_idx = np.argwhere(movieId == rate_row[1])\n",
    "    train_matrix[row_idx[0][0]][rate_row[0]-1] = rate_row[2]\n",
    "    bi.setdefault(row_idx[0][0],0)\n",
    "    bu.setdefault(rate_row[0]-1,0)\n",
    "    qi.setdefault(row_idx[0][0],random((k_sp,1))/10*(np.sqrt(k_sp))) \n",
    "    pu.setdefault(rate_row[0]-1,random((k_sp,1))/10*(np.sqrt(k_sp))) \n",
    "for rate_row in rate_test:\n",
    "    row_idx = np.argwhere(movieId == rate_row[1])\n",
    "    test_matrix[row_idx[0][0]][rate_row[0]-1] = rate_row[2]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_matrix=np.array(train_matrix.T)\n",
    "test_matrix=np.array(test_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim_user = pairwise_distances(train_matrix, metric='cosine')\n",
    "sim_mov = pairwise_distances(train_matrix.T, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_by_user(rating_matrix, sim_matrix):\n",
    "    average_rating = rating_matrix.mean(axis=1)\n",
    "    rating_substract = (rating_matrix-average_rating[:, np.newaxis])\n",
    "    a=average_rating[:, np.newaxis]\n",
    "    b=sim_matrix.dot(rating_substract)\n",
    "    c=np.array([np.abs(sim_matrix).sum(axis=1)]).T\n",
    "    prediction = a+b/c    \n",
    "    return prediction\n",
    "def predict_by_movie(rating_matrix, sim_matrix):\n",
    "    average_rating = rating_matrix.mean(axis=1)\n",
    "    rating_substract = (rating_matrix-average_rating[:, np.newaxis])\n",
    "    a=np.dot(rating_matrix,sim_matrix)\n",
    "    b=np.array([np.abs(sim_matrix).sum(axis=1)])\n",
    "    prediction = a/b    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_user = predict_by_user(train_matrix,sim_user)\n",
    "pred_movie = predict_by_movie(train_matrix,sim_mov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def r_mean_square_error(prediction,test_data):\n",
    "    prediction = prediction[test_data.nonzero()]\n",
    "    test_data = test_data[test_data.nonzero()]\n",
    "    a=mean_squared_error(prediction,test_data)\n",
    "    a=sqrt(a)\n",
    "    return sqrt(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8905866338416237\n",
      "1.8297608263191527\n"
     ]
    }
   ],
   "source": [
    "#result given by simple collabrative filtering\n",
    "\n",
    "\n",
    "print(r_mean_square_error(pred_movie,test_matrix))\n",
    "print(r_mean_square_error(pred_user,test_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.8\n",
    "k=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U,sigma,VT=np.linalg.svd(train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma_matrix=np.eye(k)*sigma[0:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix_t_opt_m=train_matrix.T.dot(U[:,:k]).dot(sigma_matrix)\n",
    "matrix_t_opt_u=train_matrix.dot(VT[:,:k]).dot(sigma_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim_mov_opt = pairwise_distances(matrix_t_opt_m, metric='cosine')\n",
    "sim_user_opt = pairwise_distances(matrix_t_opt_u, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_user_opt = predict_by_user(train_matrix,sim_user_opt)\n",
    "pred_movie_opt = predict_by_movie(train_matrix,sim_mov_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9044610563340694\n",
      "1.8416340340171184\n"
     ]
    }
   ],
   "source": [
    "#result given by left/right singular matrix with k=20\n",
    "\n",
    "\n",
    "print(r_mean_square_error(pred_movie_opt,test_matrix))\n",
    "print(r_mean_square_error(pred_user_opt,test_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find the best k by setting threshold\n",
    "\n",
    "sigma_threshold=np.sum(sigma**2)*p\n",
    "k_opt=0\n",
    "b=0\n",
    "for i in sigma:\n",
    "    if b<sigma_threshold:\n",
    "        b+=i**2\n",
    "        k_opt+=1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9034288937833506\n",
      "1.8363812535779072\n"
     ]
    }
   ],
   "source": [
    "#result given by left/right singular matrix with k_opt\n",
    "\n",
    "\n",
    "sigma_matrix_kopt=np.eye(k_opt)*sigma[0:k_opt]\n",
    "matrix_t_opt_m_k=train_matrix.T.dot(U[:,:k_opt]).dot(sigma_matrix_kopt)\n",
    "matrix_t_opt_u_k=train_matrix.dot(VT[:,:k_opt]).dot(sigma_matrix_kopt)\n",
    "sim_mov_opt_k = pairwise_distances(matrix_t_opt_m_k, metric='cosine')\n",
    "sim_user_opt_k = pairwise_distances(matrix_t_opt_u_k, metric='cosine')\n",
    "pred_user_opt_k = predict_by_user(train_matrix,sim_user_opt_k)\n",
    "pred_movie_opt_k = predict_by_movie(train_matrix,sim_mov_opt_k)\n",
    "print(r_mean_square_error(pred_movie_opt_k,test_matrix))\n",
    "print(r_mean_square_error(pred_user_opt_k,test_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pearson(a,b):\n",
    "    return 0.5+0.5*corrcoef(a.T,b.T,rowvar=0)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim_user_pears=np.zeros((rate[-1][0],rate[-1][0]))\n",
    "for i in range(rate[-1][0]):   \n",
    "    for j in range(rate[-1][0]):\n",
    "        sim_user_pears[i,j]=pearson(matrix_t_opt_u_k[i,:],matrix_t_opt_u_k[j,:])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8202229817593347\n"
     ]
    }
   ],
   "source": [
    "#result given by left/right singular matrix with k_opt and pearson similarity\n",
    "\n",
    "\n",
    "pred_user_pears = predict_by_user(train_matrix,sim_user_pears)\n",
    "print(r_mean_square_error(pred_user_pears,test_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.866824912282674\n",
      "1.8154505812046278\n"
     ]
    }
   ],
   "source": [
    "#result given by left/right singular matrix with k_opt and euclidean similarity\n",
    "\n",
    "\n",
    "sim_mov_opt_k = pairwise_distances(matrix_t_opt_m_k, metric='euclidean')\n",
    "sim_user_opt_k = pairwise_distances(matrix_t_opt_u_k, metric='euclidean')\n",
    "pred_user_opt_k = predict_by_user(train_matrix,sim_user_opt_k)\n",
    "pred_movie_opt_k = predict_by_movie(train_matrix,sim_mov_opt_k)\n",
    "print(r_mean_square_error(pred_movie_opt_k,test_matrix))\n",
    "print(r_mean_square_error(pred_user_opt_k,test_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters of svd++\n",
    "\n",
    "\n",
    "step=25\n",
    "gamma=0.05\n",
    "Lambda=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction(i,j):  \n",
    "        bi.setdefault(j,0)  \n",
    "        bu.setdefault(i,0)  \n",
    "        qi.setdefault(j,np.zeros((k_sp,1)))  \n",
    "        pu.setdefault(i,np.zeros((k_sp,1)))  \n",
    "        \n",
    "        result=ave+bi[j]+bu[i]+np.sum(qi[j]*pu[i])  \n",
    "        if result>5:  \n",
    "            return 5  \n",
    "        elif result<1:  \n",
    "            return 1  \n",
    "        return result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rmse of this step on train data is  0.957579251297\n",
      "the rmse of this step on train data is  0.88744176378\n",
      "the rmse of this step on train data is  0.86908270169\n",
      "the rmse of this step on train data is  0.857565245171\n",
      "the rmse of this step on train data is  0.849004720374\n",
      "the rmse of this step on train data is  0.842053590008\n",
      "the rmse of this step on train data is  0.83629766271\n",
      "the rmse of this step on train data is  0.830726166256\n",
      "the rmse of this step on train data is  0.824840970963\n",
      "the rmse of this step on train data is  0.81975180991\n",
      "the rmse of this step on train data is  0.814991296573\n",
      "the rmse of this step on train data is  0.809437270662\n",
      "the rmse of this step on train data is  0.805940017192\n",
      "the rmse of this step on train data is  0.801144814198\n",
      "the rmse of this step on train data is  0.796730372359\n",
      "the rmse of this step on train data is  0.792547929895\n",
      "the rmse of this step on train data is  0.787808073958\n",
      "the rmse of this step on train data is  0.784229127368\n",
      "the rmse of this step on train data is  0.780573226242\n",
      "the rmse of this step on train data is  0.777189833322\n",
      "the rmse of this step on train data is  0.773587431699\n",
      "the rmse of this step on train data is  0.771319735761\n",
      "the rmse of this step on train data is  0.767917094488\n",
      "the rmse of this step on train data is  0.765706520546\n",
      "the rmse of this step on train data is  0.763846631942\n"
     ]
    }
   ],
   "source": [
    "#training and gradient descent to optimize the loss function\n",
    "train_X=np.array(rate_train)\n",
    "for i in range(step):   \n",
    "    rmse=0.0  \n",
    "    _k_=np.random.permutation(train_X.shape[0])  \n",
    "    for j in range(train_X.shape[0]):  \n",
    "        i=_k_[j]  \n",
    "        a=train_X[i][0]  \n",
    "        b=train_X[i][1]  \n",
    "        c=train_X[i][2]  \n",
    "        d=c-prediction(a,b)  \n",
    "        rmse+=d**2  \n",
    "        bu[a]+=gamma*(d-Lambda*bu[a])  \n",
    "        bi[b]+=gamma*(d-Lambda*bi[b])  \n",
    "        e=qi[b]  \n",
    "        qi[b]+=gamma*(d*pu[a]-Lambda*qi[b])  \n",
    "        pu[a]+=gamma*(d*e-Lambda*pu[a])  \n",
    "    \n",
    "    result=np.sqrt(rmse/train_X.shape[0])\n",
    "    print (\"the rmse of this step on train data is \",result ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88667707898\n"
     ]
    }
   ],
   "source": [
    "#final result given by svd++ algorithm\n",
    "\n",
    "_sum=0  \n",
    "test_X=np.array(rate_test)  \n",
    "for i in range(test_X.shape[0]): \n",
    "    a=test_X[i][0]\n",
    "    b=test_X[i][1]\n",
    "    c=test_X[i][2]\n",
    "    rst=prediction(a,b)    \n",
    "    _sum+=(rst-c)**2  \n",
    "    result=np.sqrt(_sum/test_X.shape[0])  \n",
    "print (result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
